name: Monke â€“ single runner (build once, run all)

on:
  workflow_dispatch:
  pull_request:
    paths:
      - "monke/**"
      - ".github/workflows/**"
      - "docker/**"
      - "backend/**"
      - "frontend/**"
      - "start.sh"

concurrency:
  group: monke-${{ github.ref }}
  cancel-in-progress: true

jobs:
  all_connectors_one_runner:
    if: true # Enabled with space optimizations
    runs-on: ubuntu-latest
    environment: dev
    # Add Azure permissions for OIDC authentication
    permissions:
      id-token: write
      contents: read
      pull-requests: read

    env:
      # Use locally built test images (like public API tests)
      BACKEND_IMAGE: test-backend:latest
      FRONTEND_IMAGE: test-frontend:latest
      
      # Core configuration
      AIRWEAVE_API_URL: http://localhost:8001

      # AI provider keys for backend runtime
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
      COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
      GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
      CEREBRAS_API_KEY: ${{ secrets.CEREBRAS_API_KEY }}

    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0 # Fetch all history for change detection

      # Setup Docker layer caching (like public API tests)
      - name: Setup Docker layer caching
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-docker-${{ hashFiles('docker/docker-compose.yml') }}
          restore-keys: |
            ${{ runner.os }}-docker-

      # Pre-pull heavy Docker images in parallel (like public API tests)
      - name: Pre-pull heavy Docker images
        run: |
          echo "Pre-pulling Docker images in parallel..."
          docker pull postgres:16 &
          docker pull redis:7-alpine &
          docker pull semitechnologies/transformers-inference:sentence-transformers-all-MiniLM-L6-v2 &
          docker pull qdrant/qdrant:latest &
          docker pull temporalio/auto-setup:1.24.2 &
          docker pull temporalio/ui:2.26.2 &
          wait
          echo "All images pre-pulled successfully"

      # Build test images locally (like public API tests)
      - name: Build test images locally
        run: |
          echo "Building backend image for testing..."
          docker build -t test-backend:latest ./backend
          echo "Building frontend image for testing..."
          docker build -t test-frontend:latest ./frontend

      # Python deps (cached)
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: monke/requirements.txt

      - name: Install Python deps
        run: |
          pip install -r monke/requirements.txt
          # Install Azure dependencies if Key Vault is configured
          if [[ -n "$AZURE_KEY_VAULT_URL" ]]; then
            pip install azure-keyvault-secrets azure-identity
          fi

      # Setup environment and start services (like public API tests)
      - name: Setup environment and start services
        env:
          # Required for start.sh to skip interactive prompts
          NONINTERACTIVE: "1"
          # Set required environment variables for the containers
          AUTH0_ENABLED: "false"
          DEV_MODE: "true"
        run: |
          echo "Starting services using start.sh..."
          # Prepare a Compose override to inject AI keys into containers without touching .env
          cat > docker/compose.monke.env.yml <<'YAML'
          services:
            backend:
              environment:
                OPENAI_API_KEY: ${OPENAI_API_KEY}
                MISTRAL_API_KEY: ${MISTRAL_API_KEY}
                COHERE_API_KEY: ${COHERE_API_KEY}
                GROQ_API_KEY: ${GROQ_API_KEY}
                CEREBRAS_API_KEY: ${CEREBRAS_API_KEY}
                # Azure Key Vault for SaaS credentials
                AZURE_KEY_VAULT_URL: ${AZURE_KEY_VAULT_URL}
            temporal-worker:
              environment:
                OPENAI_API_KEY: ${OPENAI_API_KEY}
                MISTRAL_API_KEY: ${MISTRAL_API_KEY}
                COHERE_API_KEY: ${COHERE_API_KEY}
                GROQ_API_KEY: ${GROQ_API_KEY}
                CEREBRAS_API_KEY: ${CEREBRAS_API_KEY}
                # Azure Key Vault for SaaS credentials
                AZURE_KEY_VAULT_URL: ${AZURE_KEY_VAULT_URL}
          YAML

          # start.sh will create .env from .env.example and generate keys if missing
          # We pass the override so containers receive secrets from the runner env
          ./start.sh --noninteractive --compose-override docker/compose.monke.env.yml

          # The script already does health checks, but let's verify
          echo ""
          echo "Verifying we're using the correct test images:"
          docker ps --format "table {{.Names}}\t{{.Image}}" | grep airweave
          echo ""
          echo "Final verification of services:"
          docker ps

          # Backend runs on port 8001 according to start.sh
          echo "Testing backend on port 8001..."
          curl -f http://localhost:8001/health || (echo "Backend not healthy"; docker logs airweave-backend; exit 1)

          # Frontend runs on port 8080 according to start.sh
          echo "Testing frontend on port 8080..."
          curl -f http://localhost:8080 || (echo "Frontend not healthy"; docker logs airweave-frontend; exit 1)


      # Run tests using monke.sh wrapper
      - name: Run acceptance tests
        env:
          CI: true # Tells runner to use simple output
          MONKE_NO_VENV: 1 # Skip venv setup in CI
          MONKE_MAX_PARALLEL: 5
          AIRWEAVE_API_URL: http://localhost:8001

          # Core dependencies (keep these as GitHub secrets)
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
          COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          CEREBRAS_API_KEY: ${{ secrets.CEREBRAS_API_KEY }}

          # Monke test authentication
          MONKE_COMPOSIO_API_KEY: ${{ secrets.MONKE_COMPOSIO_API_KEY }}
          MONKE_COMPOSIO_PROVIDER_ID: ${{ secrets.MONKE_COMPOSIO_PROVIDER_ID }}

          # Bitbucket direct auth credentials
          MONKE_BITBUCKET_USERNAME: ${{ secrets.MONKE_BITBUCKET_USERNAME }}
          MONKE_BITBUCKET_API_TOKEN: ${{ secrets.MONKE_BITBUCKET_API_TOKEN }}
          MONKE_BITBUCKET_WORKSPACE: ${{ secrets.MONKE_BITBUCKET_WORKSPACE }}
          MONKE_BITBUCKET_REPO_SLUG: ${{ secrets.MONKE_BITBUCKET_REPO_SLUG }}

          # All SaaS app credentials (Composio configs, API tokens, etc.)
          # will be fetched from Azure Key Vault at runtime
        run: |
          # Make script executable
          chmod +x ./monke.sh

          # Create .env file first (like public API tests do)
          echo "Creating .env file from .env.example..."
          cp .env.example .env
          cp .env.example monke/.env
          
          # Run hybrid connector tests (core + changed)
          # This ensures we test the sync pipeline regardless of what changed
          echo "Running hybrid connector tests for comprehensive coverage..."
          ./monke.sh --changed

      # Cleanup Docker containers (like public API tests)
      - name: Cleanup Docker containers
        if: always()
        run: |
          echo "Cleaning up Docker containers..."
          docker compose down -v || true
          docker system prune -f || true

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: monke-logs
          path: monke/logs/**
